{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\" dir=\"auto\">\n",
    "<p dir=\"auto\"><a href=\"https://colab.research.google.com/github/encord-team/encord-notebooks/blob/main/colab-notebooks/encord_active_neptune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<div align=\"center\" dir=\"auto\">\n",
    "  <div style=\"flex: 1; padding: 10px;\">\n",
    "    <a href=\"https://join.slack.com/t/encordactive/shared_invite/zt-1hc2vqur9-Fzj1EEAHoqu91sZ0CX0A7Q\" target=\"_blank\" style=\"text-decoration:none\">\n",
    "      <img alt=\"Join us on Slack\" src=\"https://img.shields.io/badge/Join_Our_Community-4A154B?label=&logo=slack&logoColor=white\">\n",
    "    </a>\n",
    "    <a href=\"https://docs.encord.com/docs/active-overview\" target=\"_blank\" style=\"text-decoration:none\">\n",
    "      <img alt=\"Documentation\" src=\"https://img.shields.io/badge/docs-Online-blue\">\n",
    "    </a>\n",
    "    <a href=\"https://twitter.com/encord_team\" target=\"_blank\" style=\"text-decoration:none\">\n",
    "      <img alt=\"Twitter Follow\" src=\"https://img.shields.io/twitter/follow/encord_team?label=%40encord_team&amp;style=social\">\n",
    "    </a>\n",
    "    <img alt=\"Python versions\" src=\"https://img.shields.io/pypi/pyversions/encord-active\">\n",
    "    <a href=\"https://pypi.org/project/encord-active/\" target=\"_blank\" style=\"text-decoration:none\">\n",
    "      <img alt=\"PyPi project\" src=\"https://img.shields.io/pypi/v/encord-active\">\n",
    "    </a>\n",
    "    <a href=\"https://docs.encord.com/docs/active-contributing\" target=\"_blank\" style=\"text-decoration:none\">\n",
    "      <img alt=\"PRs Welcome\" src=\"https://img.shields.io/badge/PRs-Welcome-blue\">\n",
    "    </a>\n",
    "    <img alt=\"Licence\" src=\"https://img.shields.io/github/license/encord-team/encord-active\">\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÅ Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëã Hi there! \n",
    "\n",
    "This üìí notebook covers:\n",
    "- Creating an Encord Active project\n",
    "- Exploring your images\n",
    "- Curating training data\n",
    "- Training a Neural Network model and track the experiment with neptune.ai\n",
    "\n",
    "<br>\n",
    "\n",
    "> üí° Learn more about üü£ Encord Active: \n",
    "* [GitHub](https://github.com/encord-team/encord-active) \n",
    "* [Docs](https://docs.encord.com/docs/active-overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¶ Import Necessary Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "# Load torch...!!!\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Load torchvision ...!!!\n",
    "from torchvision.transforms import CenterCrop, Compose, Normalize, Resize, ToTensor\n",
    "from torchvision import datasets\n",
    "\n",
    "\n",
    "# Download Caltech101 dataset\n",
    "datasets.Caltech101(Path.cwd(), target_type=\"category\", download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üü£ Initialize Local Encord Active Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üëáüèΩ Run this utility code for Colab notebooks\n",
    "import sys\n",
    "sys.stdout.fileno = lambda: 1\n",
    "sys.stderr.fileno = lambda: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/steve/.pyenv/versions/3.10.0/envs/ea_neptune/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9144/9144 [00:06<00:00, 1330.47it/s]\n",
      "Constructing project: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9144/9144 [00:02<00:00, 3374.34it/s]\n",
      "Saving label rows: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9144/9144 [00:32<00:00, 280.50it/s]\n",
      "2023-12-14 08:12:02.734 | INFO     | encord_active.lib.metrics.execute:_execute_metrics:129 - Running metric Area\n",
      "2023-12-14 08:12:20.487 | INFO     | encord_active.lib.metrics.execute:_execute_metrics:129 - Running metric Aspect Ratio\n",
      "2023-12-14 08:12:39.871 | INFO     | encord_active.lib.metrics.execute:_execute_metrics:129 - Running metric Random Values on Images\n",
      "2023-12-14 08:12:55.865 | INFO     | encord_active.lib.metrics.execute:_execute_metrics:129 - Running metric Image Diversity\n",
      "2023-12-14 08:12:55.866 | INFO     | encord_active.lib.embeddings.embeddings:get_embeddings:287 - /Users/steve/Code/encord-notebooks/test/ea-caltech/neptune_ea_project/embeddings/cnn_images.pkl not found. Generating embeddings...\n",
      "2023-12-14 08:16:08.146 | INFO     | encord_active.lib.embeddings.embeddings:generate_image_embeddings:111 - Generating 9144 embeddings took 192.2570529170007 seconds\n",
      "2023-12-14 08:16:08.268 | INFO     | encord_active.lib.embeddings.embeddings:generate_embeddings:310 - Done!\n",
      "/Users/steve/.pyenv/versions/3.10.0/envs/ea_neptune/lib/python3.10/site-packages/umap/umap_.py:1943: UserWarning: n_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n",
      "2023-12-14 08:16:56.793 | INFO     | encord_active.lib.metrics.execute:_execute_metrics:129 - Running metric Image Singularity\n",
      "2023-12-14 08:17:27.157 | INFO     | encord_active.lib.metrics.execute:_execute_simple_metrics:147 - Running metrics Blue Values, Blur, Brightness, Contrast, Green Values, Red Values, Sharpness\n",
      "                                                    \r"
     ]
    }
   ],
   "source": [
    "from encord_active.lib.metrics.execute import run_metrics_by_embedding_type\n",
    "from encord_active.lib.metrics.metric import EmbeddingType\n",
    "from encord_active.lib.project.local import ProjectExistsError, init_local_project\n",
    "from encord_active.lib.project.project import Project\n",
    "from encord_active.public.dataset import ActiveClassificationDataset, ActiveObjectDataset\n",
    "\n",
    "\n",
    "\n",
    "# If you want to include the Caltech101 category as labels in the project\n",
    "from encord_active.lib.labels.label_transformer import (\n",
    "    ClassificationLabel,\n",
    "    DataLabel,\n",
    "    LabelTransformer,\n",
    ")\n",
    "\n",
    "\n",
    "class ClassificationTransformer(LabelTransformer):\n",
    "    def from_custom_labels(self, _, data_files: List[Path]) -> List[DataLabel]:\n",
    "        return [DataLabel(f, ClassificationLabel(class_=f.parent.name)) for f in data_files]\n",
    "    \n",
    "label_transformer = ClassificationTransformer()\n",
    "\n",
    "\n",
    "def collect_all_images(root_folder: Path) ->  list[Path]:\n",
    "    image_extensions = {\".jpg\", \".jpeg\", \".png\", \".bmp\"}\n",
    "    image_paths = []\n",
    "\n",
    "    for file_path in root_folder.glob(\"**/*\"):\n",
    "        if file_path.suffix.lower() in image_extensions:\n",
    "            image_paths.append(file_path)\n",
    "\n",
    "    return image_paths\n",
    "\n",
    "# Enter path to the downloaded torchvision dataset\n",
    "root_folder = Path(\"./caltech101\")\n",
    "\n",
    "# Path to the Encord Active project directory\n",
    "projects_dir = Path(\"./ea-caltech/\")\n",
    "\n",
    "if not projects_dir.exists():\n",
    "  projects_dir.mkdir()\n",
    "\n",
    "image_files = collect_all_images(root_folder)\n",
    "\n",
    "try:\n",
    "    project_path: Path = init_local_project(\n",
    "        files = image_files,\n",
    "        target = projects_dir,\n",
    "        project_name = \"neptune_ea_project\",\n",
    "        symlinks = False,\n",
    "        label_transformer=label_transformer\n",
    "    )\n",
    "except ProjectExistsError as e:\n",
    "    project_path = Path(\"./ea/neptune_ea_project\")\n",
    "    print(e)  # A project already exist with that name at the given path.\n",
    "\n",
    "run_metrics_by_embedding_type(\n",
    "    EmbeddingType.IMAGE,\n",
    "    data_dir=project_path,\n",
    "    use_cache_only=True\n",
    ")\n",
    "\n",
    "ea_project = Project(project_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encord Active stores and manages the data information locally from a SQLite database, and enter your project hash to ensure the module syncs the data with the right project.\n",
    "\n",
    "Your project hash and related metadata should be under ‚Äúea-caltech‚Äù >> ‚Äúneptune_ea_project‚Äù >> `project_meta.yml` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to database: sqlite:////Users/steve/Code/encord-notebooks/test/ea-caltech/encord-active.sqlite\n",
      "143\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 3, 32, 32])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "def _convert_image_to_rgb(image):\n",
    "    return image.convert(\"RGB\")\n",
    "\n",
    "SIZE = 32\n",
    "transform = Compose(\n",
    "    [\n",
    "        Resize(SIZE),\n",
    "        CenterCrop(SIZE),\n",
    "        _convert_image_to_rgb,\n",
    "        ToTensor(),\n",
    "        Normalize(\n",
    "            (0.48145466, 0.4578275, 0.40821073),\n",
    "            (0.26862954, 0.26130258, 0.27577711),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = ActiveClassificationDataset(\n",
    "    database_path=Path(\"ea-caltech/encord-active.sqlite\"),\n",
    "    project_hash=\"<REPLACE WITH YOUR PROJECT HASH>\",  # caltech\n",
    "    tag_name=\"train\",\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataloader = train_dataloader\n",
    "print(len(train_dataloader))\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n",
    "\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Track Experiment with neptune.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/stephen-encord/test-encord/e/TES-8\n"
     ]
    }
   ],
   "source": [
    "import neptune\n",
    "\n",
    "run = neptune.init_run(\n",
    "    project=\"<ENTER NEPTUNE PROJECT NAME>\",\n",
    "    api_token=\"<ENTER YOUR neptune.ai API TOKEN>\", # Best practice to save your toekn as an ENV VARIABLE\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üï∏Ô∏è Define Neural Network Architecture and Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 4.645097  [   64/ 9144], Accuracy: 0.0%\n",
      "loss: 4.607966  [ 6464/ 9144], Accuracy: 3.1%\n",
      "Logged training checkpoint to neptune.ai!\n",
      "Test Error: \n",
      " Accuracy: 10.1%, Avg loss: 4.509915 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 4.568168  [   64/ 9144], Accuracy: 7.8%\n",
      "loss: 4.528150  [ 6464/ 9144], Accuracy: 6.2%\n",
      "Logged training checkpoint to neptune.ai!\n",
      "Test Error: \n",
      " Accuracy: 12.0%, Avg loss: 4.360246 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 4.486201  [   64/ 9144], Accuracy: 7.8%\n",
      "loss: 4.462654  [ 6464/ 9144], Accuracy: 6.2%\n",
      "Logged training checkpoint to neptune.ai!\n",
      "Test Error: \n",
      " Accuracy: 14.2%, Avg loss: 4.251571 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 4.424158  [   64/ 9144], Accuracy: 7.8%\n",
      "loss: 4.406035  [ 6464/ 9144], Accuracy: 6.2%\n",
      "Logged training checkpoint to neptune.ai!\n",
      "Test Error: \n",
      " Accuracy: 17.7%, Avg loss: 4.171848 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 4.359495  [   64/ 9144], Accuracy: 9.4%\n",
      "loss: 4.357319  [ 6464/ 9144], Accuracy: 7.8%\n",
      "Logged training checkpoint to neptune.ai!\n",
      "Test Error: \n",
      " Accuracy: 19.7%, Avg loss: 4.103814 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from neptune_pytorch import NeptuneLogger\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(SIZE * SIZE * 3, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 102),  # Adjust to the number of classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "classes = train_dataset.class_names\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer, npt_logger):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss_val = loss.item()\n",
    "            correct_predictions = (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            accuracy = (correct_predictions / len(X)) * 100\n",
    "            run[npt_logger.base_namespace][\"batch/loss\"].append(loss_val)\n",
    "            run[npt_logger.base_namespace][\"batch/accuracy\"].append(accuracy)\n",
    "            print(f\"loss: {loss_val:>7f}  [{(batch + 1) * len(X):>5d}/{size:>5d}], Accuracy: {accuracy:>0.1f}%\")\n",
    "\n",
    "    npt_logger.log_checkpoint()\n",
    "    print(\"Logged training checkpoint to neptune.ai!\")\n",
    "\n",
    "def test(dataloader, model, loss_fn, npt_logger):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    accuracy = 100 * correct\n",
    "    run[npt_logger.base_namespace][\"test/loss\"].append(test_loss)\n",
    "    run[npt_logger.base_namespace][\"test/accuracy\"].append(accuracy)\n",
    "    print(f\"Test Error: \\n Accuracy: {accuracy:>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "# Initialize Neptune Logger here (npt_logger)\n",
    "\n",
    "npt_logger = NeptuneLogger(\n",
    "                            run=run,\n",
    "                            model=model,\n",
    "                            log_model_diagram=True,\n",
    "                            log_gradients=True,\n",
    "                            log_parameters=True,\n",
    "                            log_freq=30,\n",
    "                        )\n",
    "\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer, npt_logger)\n",
    "    test(test_dataloader, model, loss_fn, npt_logger)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåÉ Log Training Images to neptune.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neptune.types import File\n",
    "\n",
    "dataiter = iter(test_dataloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Predict batch of n_samples\n",
    "n_samples = 30\n",
    "imgs = images[:n_samples].to(device)\n",
    "probs = torch.nn.functional.softmax(model(imgs), dim=1)\n",
    "\n",
    "# Decode probs and log tensors as image\n",
    "for i, ps in enumerate(probs):\n",
    "    pred = classes[torch.argmax(ps)]\n",
    "    ground_truth = classes[labels[i]]\n",
    "    description = f\"pred: {pred} | ground truth: {ground_truth}\"\n",
    "\n",
    "    # Log series of tensors as image and predictions\n",
    "    run[npt_logger.base_namespace][\"predictions\"].append(\n",
    "        File.as_image(imgs[i].cpu().squeeze().permute(2, 1, 0).clip(0, 1)),\n",
    "        name=f\"{i}_{pred}_{ground_truth}\",\n",
    "        description=description,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Log neptune.ai Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down background jobs, please wait a moment...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Waiting for the remaining 1 operations to synchronize with Neptune. Do not kill this process.\n",
      "All 1 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://app.neptune.ai/stephen-encord/test-encord/e/TES-6/metadata\n"
     ]
    }
   ],
   "source": [
    "npt_logger.log_model(\"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõë Stop The Training Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n",
      "All 0 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://app.neptune.ai/stephen-encord/test-encord/e/TES-7/metadata\n"
     ]
    }
   ],
   "source": [
    "run.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Wrap up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìì This Colab notebook showed you how to: \n",
    "- Create an Encord Active project.\n",
    "- Explore your images.\n",
    "- Curate training data.\n",
    "- Train a Neural Network model and track the experiment with neptune.ai\n",
    "\n",
    "---\n",
    "\n",
    "üü£ Encord Active is an open-source framework for improving your computer vision data and model quality.  **Check out the project on [GitHub](https://github.com/encord-team/encord-active), leave a star üåü** if you like it. We welcome you to [contribute](https://docs.encord.com/docs/active-contributing) if you find something is missing.\n",
    "\n",
    "---\n",
    "\n",
    "üëâ Check out the üìñ [Encord Blog](https://encord.com/blog/) and üì∫ [YouTube](https://www.youtube.com/@encord) channel to stay up-to-date with the latest in computer vision, foundation models, active learning, and data-centric AI.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ea_new_ui",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
