{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f49161b",
   "metadata": {},
   "source": [
    "<div align=\"center\" dir=\"auto\">\n",
    "<p dir=\"auto\"><a href=\"https://colab.research.google.com/github/encord-team/encord-notebooks/blob/main/colab-notebooks/Encord_Active_Add_Custom_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<div align=\"center\" dir=\"auto\">\n",
    "  <div style=\"flex: 1; padding: 10px;\">\n",
    "    <a href=\"https://join.slack.com/t/encordactive/shared_invite/zt-1hc2vqur9-Fzj1EEAHoqu91sZ0CX0A7Q\" target=\"_blank\" style=\"text-decoration:none\">\n",
    "      <img alt=\"Join us on Slack\" src=\"https://img.shields.io/badge/Join_Our_Community-4A154B?label=&logo=slack&logoColor=white\">\n",
    "    </a>\n",
    "    <a href=\"https://docs.encord.com/docs/active-overview\" target=\"_blank\" style=\"text-decoration:none\">\n",
    "      <img alt=\"Documentation\" src=\"https://img.shields.io/badge/docs-Online-blue\">\n",
    "    </a>\n",
    "    <a href=\"https://twitter.com/encord_team\" target=\"_blank\" style=\"text-decoration:none\">\n",
    "      <img alt=\"Twitter Follow\" src=\"https://img.shields.io/twitter/follow/encord_team?label=%40encord_team&amp;style=social\">\n",
    "    </a>\n",
    "    <img alt=\"Python versions\" src=\"https://img.shields.io/pypi/pyversions/encord-active\">\n",
    "    <a href=\"https://pypi.org/project/encord-active/\" target=\"_blank\" style=\"text-decoration:none\">\n",
    "      <img alt=\"PyPi project\" src=\"https://img.shields.io/pypi/v/encord-active\">\n",
    "    </a>\n",
    "    <a href=\"https://docs.encord.com/docs/active-contributing\" target=\"_blank\" style=\"text-decoration:none\">\n",
    "      <img alt=\"PRs Welcome\" src=\"https://img.shields.io/badge/PRs-Welcome-blue\">\n",
    "    </a>\n",
    "    <img alt=\"License\" src=\"https://img.shields.io/github/license/encord-team/encord-active\">\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d5f8ff9",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <p>\n",
    "    <a align=\"center\" href=\"\" target=\"_blank\">\n",
    "      <img\n",
    "        width=\"7232\"\n",
    "        src=\"https://storage.googleapis.com/encord-notebooks/encord_active_notebook_banner.png\">\n",
    "    </a>\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99cd4d8b",
   "metadata": {},
   "source": [
    "# 🟣 Encord Active | Add Custom Embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "616ca378",
   "metadata": {},
   "source": [
    "## 🚀 Overview"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f735c771",
   "metadata": {},
   "source": [
    "Hi there, 👋.\n",
    "\n",
    "Encord Active has three different types of embeddings.\n",
    "\n",
    "1. _Image embeddings:_ are general for each image / frame in the dataset\n",
    "2. _Classification embeddings:_ are associated to specific frame level classifications\n",
    "3. _Object embeddings:_ are associated to specific objects like polygons of bounding boxes\n",
    "\n",
    "If you like, you can \"swap out\" these embeddings with your own by following the steps in this notebook.\n",
    "\n",
    "There are two sections in the notebook. One for the image embeddings and one for the objects.\n",
    "If you have classifications in your project, you should run:\n",
    "\n",
    "```\n",
    "encord-active metric run \"Image-level Annotation Quality\"\n",
    "```\n",
    "\n",
    "This will take the image level embeddings that you provided and also associate them to the classification labels.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "> 💡 Learn more about 🟣 Encord Active: \n",
    "* [GitHub](https://github.com/encord-team/encord-active) \n",
    "* [Docs](https://docs.encord.com/docs/active-overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c74cdeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "from encord_active.lib.common.iterator import DatasetIterator, Iterator\n",
    "from encord_active.lib.embeddings.dimensionality_reduction import (\n",
    "    generate_2d_embedding_data,\n",
    ")\n",
    "from encord_active.lib.embeddings.types import LabelEmbedding\n",
    "from encord_active.lib.metrics.types import EmbeddingType\n",
    "from encord_active.lib.project.project_file_structure import ProjectFileStructure\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "\n",
    "def load_my_model() -> torch.nn.Module:\n",
    "    ...  # <- HERE: Edit here to return your model\n",
    "\n",
    "\n",
    "def get_transform():\n",
    "    return (\n",
    "        ToTensor()\n",
    "    )  # <- HERE: If you have any specific transforms to apply to PIL images."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50e58bc8",
   "metadata": {},
   "source": [
    "## 🖼️ Example of Image Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5d39aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def generate_cnn_image_embeddings(iterator: Iterator) -> List[LabelEmbedding]:\n",
    "    model = load_my_model()\n",
    "    transform = get_transform()\n",
    "\n",
    "    collections: List[LabelEmbedding] = []\n",
    "    for data_unit, image in iterator.iterate(desc=\"Embedding image data.\"):\n",
    "        if image is None:\n",
    "            continue\n",
    "\n",
    "        image_pil = image.convert(\"RGB\")\n",
    "        image = transform(image_pil)\n",
    "\n",
    "        # START Embedding\n",
    "        embedding = model(image)  # <- HERE - your logic for embedding data.\n",
    "\n",
    "        if embedding is None:\n",
    "            continue\n",
    "\n",
    "        embedding = embedding.flatten().detach().numpy()  # <- should be a [d,] array.\n",
    "        # End Embedding\n",
    "\n",
    "        entry = LabelEmbedding(\n",
    "            url=data_unit[\"data_link\"],\n",
    "            label_row=iterator.label_hash,\n",
    "            data_unit=data_unit[\"data_hash\"],\n",
    "            frame=iterator.frame,\n",
    "            dataset_title=iterator.dataset_title,\n",
    "            embedding=embedding,\n",
    "            labelHash=None,\n",
    "            lastEditedBy=None,\n",
    "            featureHash=None,\n",
    "            name=None,\n",
    "            classification_answers=None,\n",
    "        )\n",
    "        collections.append(entry)\n",
    "\n",
    "    return collections\n",
    "\n",
    "\n",
    "project = Path(\"/path/to/your/project/root\")  # <- HERE: Path to the Encord Project\n",
    "pfs = ProjectFileStructure(project)\n",
    "\n",
    "iterator = DatasetIterator(project)\n",
    "embeddings = generate_cnn_image_embeddings(iterator)\n",
    "out_file = prfs.get_embeddings_file(EmbeddingType.IMAGE)\n",
    "\n",
    "with out_file.open(\"wb\") as f:\n",
    "    pickle.dump(embeddings, f)\n",
    "\n",
    "generate_2d_embedding_data(EmbeddingType.IMAGE, project)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d3fde49",
   "metadata": {},
   "source": [
    "## 🏷️ Example of Object Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddddaa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from encord_active.lib.common.utils import get_bbox_from_encord_label_object\n",
    "\n",
    "@torch.inference_mode()\n",
    "def generate_cnn_object_embeddings(iterator: Iterator) -> List[LabelEmbedding]:\n",
    "    model = get_model()\n",
    "    transform = get_transform()\n",
    "\n",
    "    embeddings: List[LabelEmbedding] = []\n",
    "    for data_unit, image in iterator.iterate(desc=\"Embedding object data.\"):\n",
    "        if image is None:\n",
    "            continue\n",
    "        \n",
    "        image_pil = image.convert(\"RGB\")\n",
    "        image = transform(image_pil)\n",
    "        \n",
    "        for obj in data_unit[\"labels\"].get(\"objects\", []):\n",
    "            if obj[\"shape\"] in [\n",
    "                ObjectShape.POLYGON.value,\n",
    "                ObjectShape.BOUNDING_BOX.value,\n",
    "                ObjectShape.ROTATABLE_BOUNDING_BOX.value,\n",
    "            ]:\n",
    "                # Crops images tightly around object\n",
    "                out = get_bbox_from_encord_label_object( \n",
    "                    obj,\n",
    "                    image.shape[2],\n",
    "                    image.shape[1],\n",
    "                )\n",
    "\n",
    "                if out is None:\n",
    "                    continue\n",
    "                \n",
    "                x, y, w, h = out\n",
    "                img_patch = image[:, y : y + h, x : x + w]\n",
    "                \n",
    "                # Compute embeddings\n",
    "                embedding = model(img_patch)\n",
    "                embedding = embedding.flatten().detach().numpy()  # <- should be a [d,] array.\n",
    "\n",
    "                last_edited_by = obj[\"lastEditedBy\"] if \"lastEditedBy\" in obj.keys() else obj[\"createdBy\"]\n",
    "                entry = LabelEmbedding(\n",
    "                    url=data_unit[\"data_link\"],\n",
    "                    label_row=iterator.label_hash,\n",
    "                    data_unit=data_unit[\"data_hash\"],\n",
    "                    frame=iterator.frame,\n",
    "                    labelHash=obj[\"objectHash\"],\n",
    "                    lastEditedBy=last_edited_by,\n",
    "                    featureHash=obj[\"featureHash\"],\n",
    "                    name=obj[\"name\"],\n",
    "                    dataset_title=iterator.dataset_title,\n",
    "                    embedding=embedding,\n",
    "                    classification_answers=None,\n",
    "                )\n",
    "\n",
    "                embeddings.append(entry)\n",
    "\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "embeddings = generate_cnn_object_embeddings(iterator)\n",
    "out_file = pfs.get_embeddings_file(EmbeddingType.OBJECT)\n",
    "\n",
    "with out_file.open(\"wb\") as f:\n",
    "    pickle.dump(embeddings, f)\n",
    "\n",
    "generate_2d_embedding_data(EmbeddingType.OBJECT, project)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4744c9dc",
   "metadata": {},
   "source": [
    "# ✅ Wrap Up: Next Steps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54067a9c",
   "metadata": {},
   "source": [
    "🟣 Encord Active is an open-source framework for computer vision model testing, evaluation, and validation.  **Check out the project on [GitHub](https://github.com/encord-team/encord-active), leave a star 🌟** if you like it. We welcome you to [contribute](https://docs.encord.com/docs/active-contributing) if you find something is missing.\n",
    "\n",
    "---\n",
    "\n",
    "👉 Check out the 📖 [Encord Blog](https://encord.com/blog/) and 📺 [YouTube](https://www.youtube.com/@encord) channel to stay up-to-date with the latest in computer vision, foundation models, active learning, and data-centric AI.\n",
    "\n",
    "---\n",
    "\n",
    "Thanks for now!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7587b03",
   "metadata": {},
   "source": [
    "### ⬅️ [*Previous Notebook*](./Encord_Active_Building_a_Custom_Metric_Function.ipynb) $~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~$ [*Next Notebook*](https://github.com/encord-team/encord-notebooks) *➡️*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
