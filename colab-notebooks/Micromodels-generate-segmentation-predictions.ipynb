{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5120227b",
   "metadata": {},
   "source": [
    "<div align=\"center\" dir=\"auto\">\n",
    "<p dir=\"auto\"><a href=\"https://colab.research.google.com/github/encord-team/encord-notebooks/blob/main/colab-notebooks/Micromodels-generate-segmentation-predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<div align=\"center\" dir=\"auto\">\n",
    "  <div style=\"flex: 1; padding: 10px;\">\n",
    "    <a href=\"https://join.slack.com/t/encordactive/shared_invite/zt-1hc2vqur9-Fzj1EEAHoqu91sZ0CX0A7Q\" target=\"_blank\" style=\"text-decoration:none\">\n",
    "      <img alt=\"Join us on Slack\" src=\"https://img.shields.io/badge/Join_Our_Community-4A154B?label=&logo=slack&logoColor=white\">\n",
    "    </a>\n",
    "    <a href=\"https://docs.encord.com/docs/active-overview\" target=\"_blank\" style=\"text-decoration:none\">\n",
    "      <img alt=\"Documentation\" src=\"https://img.shields.io/badge/docs-Online-blue\">\n",
    "    </a>\n",
    "    <a href=\"https://twitter.com/encord_team\" target=\"_blank\" style=\"text-decoration:none\">\n",
    "      <img alt=\"Twitter Follow\" src=\"https://img.shields.io/twitter/follow/encord_team?label=%40encord_team&amp;style=social\">\n",
    "    </a>\n",
    "    <img alt=\"Python versions\" src=\"https://img.shields.io/pypi/pyversions/encord-active\">\n",
    "    <a href=\"https://pypi.org/project/encord-active/\" target=\"_blank\" style=\"text-decoration:none\">\n",
    "      <img alt=\"PyPi project\" src=\"https://img.shields.io/pypi/v/encord-active\">\n",
    "    </a>\n",
    "    <a href=\"https://docs.encord.com/docs/active-contributing\" target=\"_blank\" style=\"text-decoration:none\">\n",
    "      <img alt=\"PRs Welcome\" src=\"https://img.shields.io/badge/PRs-Welcome-blue\">\n",
    "    </a>\n",
    "    <img alt=\"Licence\" src=\"https://img.shields.io/github/license/encord-team/encord-active\">\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27855bf",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <p>\n",
    "    <a align=\"center\" href=\"\" target=\"_blank\">\n",
    "      <img\n",
    "        width=\"7232\"\n",
    "        src=\"https://storage.googleapis.com/encord-notebooks/encord_active_notebook_banner.png\">\n",
    "    </a>\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c93a7a-b96f-4af5-8679-0e41c0049b3a",
   "metadata": {},
   "source": [
    "# Generate Encord Active Model Predictions Using Encord Micro-Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba32d53-3163-4805-b0a7-c09e3e092a8c",
   "metadata": {},
   "source": [
    "#### Note-1: Ontologies of the Encord Active and Encord Annotate should be the same\n",
    "#### Note-2: The data of the local Encord Active project should have been downloaded via the following CLI command:\n",
    "\n",
    "```shell\n",
    "encord-active project download-data\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88497141-7594-4c5a-b868-06e0f08d909d",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5c2d5d-c3f5-41ad-8180-0881aa34b673",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCORD_ACTIVE_PROJECT_PATH='/path/to/local/encord_active/project'\n",
    "ENCORD_SSH_KEY_PATH='ENCORD_SSH_KEY_PATH'\n",
    "ENCORD_PROJECT_HASH='ENCORD_PROJECT_HASH'\n",
    "ENCORD_MODEL_ITERATION_HASH='ENCORD_MODEL_ITERATION_HASH'\n",
    "\n",
    "BATCH_SIZE=24\n",
    "CONFIDENCE_THRESHOLD=0.6\n",
    "IOU_THRESHOLD=0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e81909a-901a-413e-b390-7eea91ed8062",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281f2583-f422-4667-8661-b0ad982148bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from encord import EncordUserClient, Project\n",
    "from tqdm import tqdm\n",
    "\n",
    "from encord_active.lib.common.iterator import DatasetIterator\n",
    "from encord_active.lib.db.predictions import Format, ObjectDetection, Prediction\n",
    "from encord_active.lib.project.project_file_structure import ProjectFileStructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d4783b-48f8-409f-b76d-d6022f22aa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_client = EncordUserClient.create_with_ssh_private_key(Path(ENCORD_SSH_KEY_PATH).expanduser().read_text())\n",
    "project: Project = user_client.get_project(ENCORD_PROJECT_HASH)\n",
    "\n",
    "ea_project_fs: ProjectFileStructure = ProjectFileStructure(ENCORD_ACTIVE_PROJECT_PATH)\n",
    "iterator = DatasetIterator(ea_project_fs.project_dir)\n",
    "\n",
    "ontology = json.loads(ea_project_fs.ontology.read_text(encoding=\"utf-8\"))\n",
    "ontology_featureHashes = [obj[\"featureNodeHash\"] for obj in ontology.get(\"objects\")]\n",
    "\n",
    "predictions_to_store = []\n",
    "file_paths = []\n",
    "data_units = []\n",
    "\n",
    "image_extensions = ['.png', '.jpg', '.bmp', '.jpeg', '']  # include '' for files without extensions\n",
    "video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.flv', '.wmv']\n",
    "\n",
    "pbar = tqdm(total=iterator.length, desc=\"Running inference\", leave=True)\n",
    "for counter, f in enumerate(ea_project_fs.local_data_store.iterdir()):\n",
    "    if f.suffix in image_extensions and f.suffix not in video_extensions:\n",
    "        file_paths.append(f.as_posix())\n",
    "        data_units.append(f.name)\n",
    "\n",
    "        if (counter + 1) % BATCH_SIZE == 0 or counter + 1 == len(file_paths):\n",
    "            try:\n",
    "                inference_results = project.model_inference(\n",
    "                    ENCORD_MODEL_ITERATION_HASH,\n",
    "                    file_paths=file_paths,\n",
    "                    conf_thresh=CONFIDENCE_THRESHOLD,\n",
    "                    iou_thresh=IOU_THRESHOLD,\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "\n",
    "            for inference_result, du in zip(inference_results, data_units):\n",
    "                for obj in inference_result[\"predictions\"][\"0\"][\"objects\"]:\n",
    "\n",
    "                    if obj[\"shape\"] != \"polygon\":\n",
    "                        print(f\"prediction is not in `polygon` type (it is in {obj['shape']} type), skipping...\")\n",
    "                        continue\n",
    "\n",
    "                    if obj[\"featureHash\"] not in ontology_featureHashes:\n",
    "                        print(\n",
    "                            f\"'{obj['name']}' with featureHash '{obj['featureHash']}' is not available in the ontology of\"\n",
    "                            f\" the Encord Active project.\"\n",
    "                        )\n",
    "                        continue\n",
    "\n",
    "                    polygon_points = [[key, [value[\"x\"], value[\"y\"]]] for key, value in obj[\"polygon\"].items()]\n",
    "                    polygon_points_sorted = sorted(polygon_points, key=lambda x: int(x[0]))\n",
    "                    polygon = np.array([item[1] for item in polygon_points_sorted])\n",
    "\n",
    "                    prediction = Prediction(\n",
    "                        data_hash=du[\"data_hash\"],\n",
    "                        confidence=obj[\"confidence\"],\n",
    "                        object=ObjectDetection(\n",
    "                            format=Format.POLYGON,\n",
    "                            data=polygon,\n",
    "                            feature_hash=obj[\"featureHash\"],\n",
    "                        ),\n",
    "                    )\n",
    "                    predictions_to_store.append(prediction)\n",
    "\n",
    "            file_paths = []\n",
    "            data_units = []\n",
    "\n",
    "    pbar.update(1)\n",
    "\n",
    "prediction_file = f\"predictions_{ENCORD_MODEL_ITERATION_HASH[:8]}.pkl\"\n",
    "with open((ea_project_fs.project_dir / prediction_file), \"wb\") as f:\n",
    "    pickle.dump(predictions_to_store, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cc7c18-93a6-4483-a2e6-ab997bfa07f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(ea_project_fs.project_dir.as_posix()) \n",
    "! encord-active import predictions {prediction_file}\n",
    "\n",
    "print(\"\\n✅︎ Predictions are imported successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
