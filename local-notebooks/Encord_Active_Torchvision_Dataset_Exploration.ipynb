{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaxG4fvPK5dn"
      },
      "source": [
        "<div align=\"center\" dir=\"auto\">\n",
        "<p dir=\"auto\"><a href=\"https://colab.research.google.com/github/encord-team/encord-notebooks/blob/main/colab-notebooks/Encord_Active_Torchvision_Dataset_Exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "<a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/1a088dbe61584d1b213517c05e313c765ca127ce21118626b2d0db0b8f573235/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f656e636f72642d7465616d2f656e636f72642d616374697665\"><img src=\"https://camo.githubusercontent.com/1a088dbe61584d1b213517c05e313c765ca127ce21118626b2d0db0b8f573235/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f656e636f72642d7465616d2f656e636f72642d616374697665\" alt=\"License\" data-canonical-src=\"https://img.shields.io/github/license/encord-team/encord-active\" style=\"max-width: 100%;\"></a>\n",
        "<a href=\"https://www.piwheels.org/project/encord-active/\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/ad0f13bbb94beadb953a46e51cee0db17ade62e4deb8c306e36a7addfa69d18f/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f656e636f72642d616374697665\" alt=\"PyPi project\" data-canonical-src=\"https://img.shields.io/pypi/v/encord-active\" style=\"max-width: 100%;\"></a>\n",
        "<a target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://camo.githubusercontent.com/890ceffab6602e1a6ecac875e179b3984708f98b0a91293e6c632752d11bad7e/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f656e636f72642d616374697665\"><img src=\"https://camo.githubusercontent.com/890ceffab6602e1a6ecac875e179b3984708f98b0a91293e6c632752d11bad7e/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f656e636f72642d616374697665\" alt=\"PyPi version\" data-canonical-src=\"https://img.shields.io/pypi/pyversions/encord-active\" style=\"max-width: 100%;\"></a>\n",
        "\n",
        "<a href=\"https://docs.encord.com/docs/active-overview\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/457447b616a4e5aecccd5351fa78d41ce828901e395b935ad2a94d94db75e5d0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6f6e6c696e652d626c7565\" alt=\"docs\" data-canonical-src=\"https://img.shields.io/badge/docs-online-blue\" style=\"max-width: 100%;\"></a>\n",
        "<a href=\"https://join.slack.com/t/encordactive/shared_invite/zt-1hc2vqur9-Fzj1EEAHoqu91sZ0CX0A7Q\" target=\"_blank\" style=\"text-decoration:none\">\n",
        "<img alt=\"Join us on Slack\" src=\"https://img.shields.io/badge/Join_Our_Community-4A154B?label=&logo=slack&logoColor=white\">\n",
        "</a>\n",
        "<a href=\"https://github.com/encord-team/encord-notebooks/blob/main/local-notebooks/Encord_Active_Torchvision_Dataset_Exploration.ipynb\" rel=\"nofollow\"><img src=\"https://badges.aleen42.com/src/github.svg\" alt=\"&quot;Encord Notebooks;\" data-canonical-src=\"https://badges.aleen42.com/src/github.svg\" style=\"max-width: 100%;\"></a>\n",
        "\n",
        "\n",
        "</p>\n",
        "<p dir=\"auto\">\n",
        "<a href=\"https://twitter.com/encord_team\" rel=\"nofollow\"><img src=\"https://camo.githubusercontent.com/c7ea37e4d1f0c2e900069152f5990d3bcef4a69c97dede26f08d588958410bd8/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f656e636f72645f7465616d3f6c6162656c3d253430656e636f72645f7465616d267374796c653d736f6369616c\" alt=\"Twitter Follow\" data-canonical-src=\"https://img.shields.io/twitter/follow/encord_team?label=%40encord_team&amp;style=social\" style=\"max-width: 100%;\"></a></p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3J2CLN4f0qt0"
      },
      "source": [
        "<div align=\"center\">\n",
        "  <p>\n",
        "    <a align=\"center\" href=\"\" target=\"_blank\">\n",
        "      <img\n",
        "        width=\"7232\"\n",
        "        src=\"https://storage.googleapis.com/encord-notebooks/encord_active_notebook_banner.png\">\n",
        "    </a>\n",
        "  </p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXywCRMtLCch"
      },
      "source": [
        "# üü£ Encord Active | üî¶ Torchvision Dataset Exploration\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmaPL0STLnez"
      },
      "source": [
        "## üöÄ Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5rxwf3cMcZr"
      },
      "source": [
        "üëã Hi there! In this notebook, you will use Encord Active to explore the quality of a dataset from the built-in samples in the [`torchvision.datasets`](https://pytorch.org/vision/stable/datasets.html) module.\n",
        "\n",
        "> ‚ö†Ô∏è **Prerequisites:** you should have `encord-active` [installed](https://docs.encord.com/docs/active-overview) in your environment.\n",
        "\n",
        "This üìí notebook will cover:\n",
        "* Downloading a dataset through the built-in datasets in the `torchvision.datasets` module.\n",
        "* Creating an Encord Active project.\n",
        "* Inspecting problematic images in the dataset.\n",
        "* Exploring more features with Encord Active UI.\n",
        "\n",
        "<br>\n",
        "\n",
        "> üí° Learn more about üü£ Encord Active:\n",
        "* [GitHub](https://github.com/encord-team/encord-active)\n",
        "* [Docs](https://docs.encord.com/docs/active-overview)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD0LBtnK-REL"
      },
      "source": [
        "## üì• Install üü£ Encord-Active"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y79puNuhpZp"
      },
      "source": [
        "üìå  `python3.9`, `python3.10`, and `python3.11` are the version requirements to run üü£Encord Active."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APt_Z1BUU-xI"
      },
      "outputs": [],
      "source": [
        "# Assert that python is 3.9 or 3.10 instead\n",
        "import sys\n",
        "assert sys.version_info.minor in [9, 10, 11], \"Encord Active only supported for python 3.9, 3.10, and 3.11.\"\n",
        "\n",
        "!pip install encord-active &> /dev/null\n",
        "!encord-active --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPEcbw2l5f1u"
      },
      "outputs": [],
      "source": [
        "#@title Optional: Install `numpy 1.23.5` as a utility library for this project.\n",
        "\n",
        "%pip install -U -q numpy==1.23.5 # If you encounter a numpy error later in the code, comment/uncomment this line, and run after this point"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXDKGS6G-W2-"
      },
      "source": [
        "# üì® Download TorchVision Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiKeDVCWYK0l"
      },
      "source": [
        "You can install any torhcvision dataset. Here, we will install [Caltech101](https://pytorch.org/vision/stable/generated/torchvision.datasets.Caltech101.html#torchvision.datasets.Caltech101) dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPkyi5wb_Vws"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from torchvision import datasets\n",
        "\n",
        "datasets.Caltech101(Path.cwd(), target_type=\"category\", download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXxhLhin_WUT"
      },
      "source": [
        "# üîß Create an üü£ Encord Active project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kxQ0AoEZI0x"
      },
      "source": [
        "## üëâ Add the Dataset to Your üü£ Encord Active Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRR8bPc_t9UJ"
      },
      "source": [
        "The code below essentially sets up a project using Encord Active, initializes it with image files, and then runs metrics on the project's data.\n",
        "\n",
        "- Obtain a list of all the Caltech 101 image files from the dataset directory with the `collect_all_images` that takes a root folder path as input and returns a list of Path objects representing image files within the root folder\n",
        "\n",
        "- Initialize a local project using Encord Active's `init_local_project` function\n",
        "\n",
        "- Creates a project in the specified `projects_dir` directory with the provided image files and project name\n",
        "\n",
        "- Call the [`run_metrics_by_embedding_type`](https://docs.encord.com/active/docs/sdk/run-metrics/#running-data-or-label-metrics-only) function to run metrics for the image embeddings (EmbeddingType.IMAGE). The metrics will be executed on the data in `project_path`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCBKNbXN5sZ0"
      },
      "outputs": [],
      "source": [
        "from encord_active.lib.metrics.execute import run_metrics, run_metrics_by_embedding_type\n",
        "from encord_active.lib.metrics.metric import EmbeddingType\n",
        "from encord_active.lib.project.local import ProjectExistsError, init_local_project\n",
        "from encord_active.lib.project.project import Project\n",
        "\n",
        "def collect_all_images(root_folder: Path) ->  list[Path]:\n",
        "    image_extensions = {\".jpg\", \".jpeg\", \".png\", \".bmp\"}\n",
        "    image_paths = []\n",
        "\n",
        "    for file_path in root_folder.glob(\"**/*\"):\n",
        "        if file_path.suffix.lower() in image_extensions:\n",
        "            image_paths.append(file_path)\n",
        "\n",
        "    return image_paths\n",
        "\n",
        "# Enter path to the downloaded torchvision dataset\n",
        "root_folder = Path(\"./caltech101\")\n",
        "projects_dir = Path(\"./ea/\")\n",
        "\n",
        "if not projects_dir.exists():\n",
        "  projects_dir.mkdir()\n",
        "\n",
        "image_files = collect_all_images(root_folder)\n",
        "\n",
        "try:\n",
        "    project_path: Path = init_local_project(\n",
        "        files = image_files,\n",
        "        target = projects_dir,\n",
        "        project_name = \"sample_ea_project\",\n",
        "        symlinks = False,\n",
        "    )\n",
        "except ProjectExistsError as e:\n",
        "    project_path = Path(\"./ea/sample_ea_project\")\n",
        "    print(e)  # A project already exist with that name at the given path.\n",
        "\n",
        "run_metrics_by_embedding_type(\n",
        "    EmbeddingType.IMAGE,\n",
        "    data_dir=project_path,\n",
        "    use_cache_only=True\n",
        ")\n",
        "\n",
        "ea_project = Project(project_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLlodjncU8f4"
      },
      "source": [
        "# üì• Import helper functions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dkz0oi6BwK8H"
      },
      "source": [
        "Now import some helper functions from Encord Active and with visualization libraries to visualize the images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INU_TIhxU_bn"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "from encord_active.lib.charts.data_quality_summary import create_image_size_distribution_chart, create_outlier_distribution_chart\n",
        "from encord_active.lib.dataset.summary_utils import get_all_image_sizes, get_metric_summary, get_median_value_of_2d_array\n",
        "from encord_active.lib.metrics.utils import load_available_metrics\n",
        "from encord_active.lib.dataset.outliers import MetricsSeverity, get_all_metrics_outliers\n",
        "from encord_active.lib.common.image_utils import load_or_fill_image\n",
        "from encord_active.lib.charts.histogram import get_histogram\n",
        "\n",
        "def plot_top_k_images(metric_name: str, metrics_data_summary: MetricsSeverity, project: Project, k: int, show_description: bool = False, ascending: bool = True):\n",
        "    metric_df = metrics_data_summary.metrics[metric_name].df\n",
        "    metric_df.sort_values(by='score', ascending=ascending, inplace=True)\n",
        "\n",
        "    for _, row in metric_df.head(k).iterrows():\n",
        "        image = load_or_fill_image(row, project.file_structure)\n",
        "        plt.imshow(image)\n",
        "        plt.show()\n",
        "        print(f\"{metric_name} score: {row['score']}\")\n",
        "        if show_description:\n",
        "          print(f\"{row['description']}\")\n",
        "\n",
        "def plot_metric_distribution(metric_name: str, metric_data_summary: MetricsSeverity):\n",
        "    fig = px.histogram(metrics_data_summary.metrics[metric_name].df, x=\"score\", nbins=50)\n",
        "\n",
        "    fig.update_layout(title=f\"{metric_name} score distribution\", bargap=0.2)\n",
        "    fig.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlcKNEnUUnKI"
      },
      "source": [
        "# üîî Plot image size distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDm0oVjzT8ZO"
      },
      "outputs": [],
      "source": [
        "image_sizes = get_all_image_sizes(ea_project.file_structure)\n",
        "median_image_dimension = get_median_value_of_2d_array(image_sizes)\n",
        "\n",
        "fig = create_image_size_distribution_chart(image_sizes)\n",
        "\n",
        "print(f\"Total images in the dataset: {len(image_sizes)}\")\n",
        "print(f\"Median image sizes: {median_image_dimension[0]}x{median_image_dimension[1]}\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8itAs0SUxMJ"
      },
      "source": [
        "# üìà Show total outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0ULGHxRUWsH"
      },
      "outputs": [],
      "source": [
        "available_metrics = load_available_metrics(ea_project.file_structure.metrics)\n",
        "metrics_data_summary = get_metric_summary(available_metrics)\n",
        "all_metrics_outliers = get_all_metrics_outliers(metrics_data_summary)\n",
        "fig = create_outlier_distribution_chart(all_metrics_outliers, \"tomato\", 'orange')\n",
        "\n",
        "print(f'Total severe outliers: {metrics_data_summary.total_unique_severe_outliers} \\n'\n",
        "      f'Total moderate outliers: {metrics_data_summary.total_unique_moderate_outliers}')\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdAHQn-vbfeo"
      },
      "source": [
        "# üßê Inspect problematic images\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9Kb0wQXV8TN"
      },
      "source": [
        "Now you will have to inspect the dataset for problematic images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FT5I5dGhVZNb"
      },
      "outputs": [],
      "source": [
        "# First, get the list of available metrics\n",
        "[metric.name for metric in available_metrics]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjtOB7Jzr7Dl"
      },
      "source": [
        "## üëÅÔ∏è Visualize score distributions based on metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIfht5swsAHe"
      },
      "outputs": [],
      "source": [
        "for metric in available_metrics:\n",
        "  plot_metric_distribution(metric.name, metrics_data_summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbuCMR3IiA8f"
      },
      "source": [
        "## ‚ñ™Ô∏è Get the smallest images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiFuNRCogHWd"
      },
      "outputs": [],
      "source": [
        "plot_top_k_images('Area', metrics_data_summary, ea_project, k=5, ascending=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBjOfkIviFta"
      },
      "source": [
        "## ‚¨õÔ∏è Get the biggest images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziYYWe82hxzg"
      },
      "outputs": [],
      "source": [
        "plot_top_k_images('Area', metrics_data_summary, ea_project, k=5, ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRznGY3OiMej"
      },
      "source": [
        "## üå´Ô∏è Get the blurriest images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOLwSfV5iRsw"
      },
      "outputs": [],
      "source": [
        "plot_top_k_images('Blur', metrics_data_summary, ea_project, k=5, ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9uj-9YairJi"
      },
      "source": [
        "## üîÜ Get the brightest images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuezcOvwivGX"
      },
      "outputs": [],
      "source": [
        "plot_top_k_images('Brightness', metrics_data_summary, ea_project, k=5, ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJTm7fGmmmpX"
      },
      "source": [
        "## ‚ñì Get the darkest images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bqBxlZ0mqFt"
      },
      "outputs": [],
      "source": [
        "plot_top_k_images('Brightness', metrics_data_summary, ea_project, k=5, ascending=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "957ribVtjVZo"
      },
      "source": [
        "## üöÄ Get the least unique images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACyNR_S2iyT1"
      },
      "outputs": [],
      "source": [
        "plot_top_k_images('Image Singularity', metrics_data_summary, ea_project, k=15, show_description=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDwoY8JVwnnA"
      },
      "source": [
        "## ‚ñ´Ô∏è Get the images that have the smallest aspect ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRlu5blZwVH0"
      },
      "outputs": [],
      "source": [
        "plot_top_k_images('Aspect Ratio', metrics_data_summary, ea_project, k=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "254nYRNAwxbX"
      },
      "source": [
        "## üî≥ Get the images that have the biggest aspect ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbJpit1EwyBV"
      },
      "outputs": [],
      "source": [
        "plot_top_k_images('Aspect Ratio', metrics_data_summary, ea_project, k=10, ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ap6XhG2yM45"
      },
      "source": [
        "# ‚úÖ Wrap Up: Explore more features with üü£ Encord Active UI\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8QDqSA6qNxA"
      },
      "source": [
        "This was just a small part of Encord Active's capabilities. Use Encord Active app to explore more of your dataset, labels, and model performance via easy to use user interface.\n",
        "\n",
        "\n",
        "With the Encord Active UI, you can:\n",
        "\n",
        "* Understand the data and label distribution.\n",
        "* Search through data in natural language.\n",
        "* Detect exact and near duplicate images.\n",
        "* Detect label errors and biases.\n",
        "* Gain insights into your model‚Äôs weak areas.\n",
        "* Generate model explainability reports.\n",
        "* Test, validate, and evaluate your models with advanced error analysis.\n",
        "\n",
        "<br>\n",
        "\n",
        "![Encord Active UI](https://images.prismic.io/encord/73635182-4f04-4299-a992-a4d383e19765_image2.gif?auto=compress,format)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqjUr2ZYy5PZ"
      },
      "source": [
        "üü£ Encord Active is an open source toolkit to prioritize the most valuable image data for labeling to supercharge model performance! **Check out the project on [GitHub](https://github.com/encord-team/encord-active), leave a star üåü** if you like it. We welcome you to [contribute](https://docs.encord.com/docs/active-contributing) if you find something is missing.\n",
        "\n",
        "---\n",
        "\n",
        "üëâ Check out the üìñ [Encord Blog](https://encord.com/blog/) and üì∫ [YouTube](https://www.youtube.com/@encord) channel to stay up-to-date with the latest in computer vision, foundation models, active learning, and data-centric AI.\n",
        "\n",
        "---\n",
        "\n",
        "Thanks for now!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmzNTiz2q3ya"
      },
      "source": [
        "# ‚è≠Ô∏è Next: Learn how to use üü£ Encord Active to explore ü§ó Face Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUFw6ClerSQU"
      },
      "source": [
        "What do you think you should check out next? üëÄ Learn how to use Encord Active to explore Hugging Face Datasets. The Colab notebook will cover:\n",
        "\n",
        "* Using ü§ó Datasets to download and generate the dataset.\n",
        "* Creating an Encord Active project.\n",
        "* Inspecting problematic images in the dataset.\n",
        "* Exploring more features with Encord Active UI.\n",
        "\n",
        "### $~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~$ *üëá*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56xRVycX0M1W"
      },
      "source": [
        "### ‚¨ÖÔ∏è [*Previous Notebook*](./02_Encord_Active___Import_project_(self_hosting).ipynb) $~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~$ [*Next Notebook*](./Encord_Active_HuggingFace_Dataset_Exploration.ipynb) *‚û°Ô∏è*"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "qD0LBtnK-REL"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
